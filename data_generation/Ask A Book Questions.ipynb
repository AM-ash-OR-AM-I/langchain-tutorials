{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d615a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypdf in /usr/local/python/3.10.4/lib/python3.10/site-packages (3.8.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# pip install langchain --upgrade\n",
    "# Version: 0.0.164\n",
    "\n",
    "! pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2d3e92ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF Loaders. If unstructured gives you a hard time, try PyPDFLoader\n",
    "from langchain.document_loaders import UnstructuredPDFLoader, OnlinePDFLoader, PyPDFLoader\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5166d759",
   "metadata": {},
   "source": [
    "### Load your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b4a2d6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"../data/UHV Text Book.pdf\")\n",
    "\n",
    "## Other options for loaders \n",
    "# loader = UnstructuredPDFLoader(\"../data/field-guide-to-data-science.pdf\")\n",
    "# loader = OnlinePDFLoader(\"https://wolfpaulus.com/wp-content/uploads/2017/05/field-guide-to-data-science.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bcdac23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec20e47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b4fd7c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 314 document(s) in your data\n",
      "There are 137 characters in your document\n"
     ]
    }
   ],
   "source": [
    "# Note: If you're using PyPDFLoader then it will split by page for you already\n",
    "print (f'You have {len(data)} document(s) in your data')\n",
    "print (f'There are {len(data[0].page_content)} characters in your document')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8af9b604",
   "metadata": {},
   "source": [
    "### Chunk your data up into smaller documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3c6f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: If you're using PyPDFLoader then we'll be splitting for the 2nd time.\n",
    "# This is optional, test out on your own data.\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=50)\n",
    "texts = text_splitter.split_documents(data)\n",
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "879873a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now you have 488 documents\n"
     ]
    }
   ],
   "source": [
    "print (f'Now you have {len(texts)} documents')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "838b2843",
   "metadata": {},
   "source": [
    "### Create embeddings of your documents to get ready for semantic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "373e695a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/pinecone/index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "# Why is it used\n",
    "from langchain.vectorstores import Chroma, Pinecone\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "import pinecone\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e093ef3",
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "# Check to see if there is an environment variable with you API keys, if not, use what you put below\n",
    "OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY')\n",
    "PINECONE_API_KEY = os.environ.get('PINECONE_API_KEY')\n",
    "PINECONE_API_ENV = os.environ.get('PINECONE_API_ENV', \"us-west1-gcp-free\") # You may need to switch with your env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e0d1c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index(index_name):\n",
    "    pinecone.create_index(index_name, dimension=1536,  metric='cosine')\n",
    "\n",
    "def delete_index(index_name):\n",
    "    pinecone.delete_index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0deb2f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize pinecone\n",
    "pinecone.init(\n",
    "    api_key=PINECONE_API_KEY,  # find at app.pinecone.io\n",
    "    environment=PINECONE_API_ENV  # next to api key in console\n",
    ")\n",
    "index_name = \"uhv-book-index\" # put in the name of your pinecone index here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ea006c12",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73b17893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No need to load any pdf, use existing index to query.\n",
    "def get_docs_from_exsting_index():\n",
    "    return Pinecone.from_existing_index(index_name=index_name, embedding=embeddings)\n",
    "\n",
    "# Need to load pdf first.\n",
    "def get_docs_from_text():\n",
    "    return Pinecone.from_texts(texts=[doc.page_content for doc in texts], metadatas=[doc.metadata for doc in texts], embedding=embeddings, index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "388988ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch = get_docs_from_exsting_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf821d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# docsearch = Pinecone.from_existing_index(index_name=\"langchain1\", embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "72649ec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain.vectorstores.pinecone.Pinecone at 0x7fecdf9c9780>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docsearch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3c35dcd9",
   "metadata": {},
   "source": [
    "### Query those docs to get your answer back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f051337b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.question_answering import load_qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b9b1c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Answer the question in 50-90 words. Just write answer don't use \"based on given context\".\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    template = prompt_template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "#Load an LLM\n",
    "# llm = OpenAI(temperature=0, openai_api_key=OPENAI_API_KEY)\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model_name=\"gpt-3.5-turbo\",            \n",
    ")\n",
    "\n",
    "#Setup chain\n",
    "chain = load_qa_chain(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    prompt = prompt # Add custom prompt\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f2f707f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['context', 'question'], output_parser=None, partial_variables={}, template='\\nUse the following pieces of context to answer the question at the end. If you don\\'t know the answer, just say that you don\\'t know, don\\'t try to make up an answer. Answer the question in 50-90 words. Just write answer don\\'t use \"based on given context\".\\n\\n{context}\\n\\nQuestion: {question}\\nAnswer:\\n', template_format='f-string', validate_template=True)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.llm_chain.prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba085969",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"../data/UHV Question Bank_single_line.pdf\")\n",
    "docs = loader.load()\n",
    "pages =\"\".join(doc.page_content for doc in docs)\n",
    "queries = [query.strip() for query in pages.split(\"\\n\") if query.strip()]\n",
    "queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2fcfb0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def save_answer(answers: dict, file_name: str):\n",
    "    with open(f\"../data/{file_name}\", \"w\", encoding=\"utf-8\") as fp:\n",
    "        json.dump(answers, fp, indent=2, ensure_ascii=True)\n",
    "\n",
    "def read_answers(file_name: str) -> dict:\n",
    "    with open(f\"../data/{file_name}\", \"r\") as fp:\n",
    "        answers = json.load(fp)\n",
    "        return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7287f58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_json_to_md(file_name=\"UHV_Answers_gpt-3.5-turbo.json\"):\n",
    "    answers = read_answers(file_name)\n",
    "    lines= []\n",
    "    for question, answer_details in answers.items():\n",
    "        answer = answer_details.get(\"answer\")\n",
    "        pages = answer_details.get(\"pages\")\n",
    "        lines.append(f\"### {question}\\n\")\n",
    "        lines.append(f\"{answer}\\n\")\n",
    "        lines.append(f\" - Source: {pages}\\n\\n\\n\")\n",
    "    with open(\"../data/answers.md\", \"w\") as f:\n",
    "        f.writelines(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "11d428d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IndexDescription(name='uhv-book-index', metric='cosine', replicas=1, dimension=1536.0, shards=1, pods=1, pod_type='p1', status={'ready': True, 'state': 'Ready'}, metadata_config=None, source_collection='')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pinecone.describe_index(index_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "21b3c80f",
   "metadata": {},
   "source": [
    "### Multiple Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfd2b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "file_name = \"UHV_Answers_gpt-3.5-turbo.json\"\n",
    "answers_dict = read_answers(file_name=file_name)\n",
    "sub_queries = queries[53:]\n",
    "for query in sub_queries:\n",
    "    docs = docsearch.similarity_search(query)\n",
    "    details = defaultdict()\n",
    "    answer = chain.run(input_documents=docs, question=query)\n",
    "    print(f\"{query = }\\n{answer = }\\n\")\n",
    "    details[\"answer\"] = answer\n",
    "    details[\"pages\"] = [int(doc.metadata.get(\"page\"))+1 for doc in docs]\n",
    "    answers_dict[query] = details\n",
    "    save_answer(answers_dict, file_name = file_name)\n",
    "convert_json_to_md()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0e43b744",
   "metadata": {},
   "source": [
    "### Single query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3e43cf17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search similar docs\n",
      "Running LLM\n",
      "defaultdict(None, {'answer': 'Love is the feeling of being related to everyone and seeing each and everyone as our relative. It is a feeling of being connected to others and wanting their happiness. Affection, on the other hand, is the recognition of the feeling that the other is related to me. It comes naturally once trust and respect are recognized in a relationship. Love is a broader concept that encompasses affection, as it extends to all beings, while affection is specific to individual relationships.', 'pages': [187, 185, 186, 186]})\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "file_name = \"UHV_Answers_gpt-3.5-turbo.json\"\n",
    "answers_dict = read_answers(file_name=file_name)\n",
    "\n",
    "\n",
    "query = \"Distinguish between love and affection?\"\n",
    "\n",
    "print(\"Search similar docs\")\n",
    "docs = docsearch.similarity_search(query)\n",
    "details = defaultdict()\n",
    "\n",
    "print(\"Running LLM\")\n",
    "answer = chain.run(input_documents=docs, question=query)\n",
    "# print(f\"{query = }\\n{answer = }\\n\")\n",
    "\n",
    "details[\"answer\"] = answer\n",
    "details[\"pages\"] = [int(doc.metadata.get(\"page\"))+1 for doc in docs]\n",
    "print(details)\n",
    "answers_dict[query] = details\n",
    "# print(answers_dict)\n",
    "save_answer(answers_dict, file_name = file_name)\n",
    "convert_json_to_md()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713a77cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
